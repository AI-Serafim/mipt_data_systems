{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92818fc",
   "metadata": {},
   "source": [
    "# Домашнее задание 6. Автоматизация расчетов с помощью Apache AirFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ba04b",
   "metadata": {},
   "source": [
    "## Шаг 1. Создать Airflow DAG, который будет ежедневно выполнять следующие действия:\n",
    "загружать данные из файлов с локальной директории в соответствующие таблицы (параллельные task-и)\n",
    "- о клиентах — customer;\n",
    "- о продуктах — product;\n",
    "- о заказах — orders;\n",
    "- связывающие заказы и продукты — order_items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad8130",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from datetime import datetime\n",
    "from pendulum import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"/opt/airflow/data\"\n",
    "CONN_ID = \"postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d23d9a",
   "metadata": {},
   "source": [
    "### Создание таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDL_SQL = \"\"\"CREATE TABLE IF NOT EXISTS public.customer(\n",
    "    customer_id           INT PRIMARY KEY,\n",
    "    first_name            VARCHAR(50)  NOT NULL,\n",
    "    last_name             VARCHAR(50),\n",
    "    gender                VARCHAR(10),\n",
    "    dob                   DATE,\n",
    "    job_title             VARCHAR(200),\n",
    "    job_industry_category VARCHAR(50),\n",
    "    wealth_segment        VARCHAR(30)  NOT NULL,\n",
    "    deceased_indicator    BOOLEAN      NOT NULL,\n",
    "    owns_car              BOOLEAN      NOT NULL,\n",
    "    address               VARCHAR(200) NOT NULL,\n",
    "    postcode              VARCHAR(10)  NOT NULL,\n",
    "    state                 VARCHAR(50)  NOT NULL,\n",
    "    country               VARCHAR(50)  NOT NULL,\n",
    "    property_valuation    SMALLINT     NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.product_stage (\n",
    "    product_id     INT,\n",
    "    brand          VARCHAR(50),\n",
    "    product_line   VARCHAR(20),\n",
    "    product_class  VARCHAR(10),\n",
    "    product_size   VARCHAR(10),\n",
    "    list_price     NUMERIC(10,2),\n",
    "    standard_cost  NUMERIC(10,2)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.orders (\n",
    "    order_id     INT         PRIMARY KEY,\n",
    "    customer_id  INT         NOT NULL,\n",
    "    order_date   DATE        NOT NULL,\n",
    "    online_order BOOLEAN,\n",
    "    order_status VARCHAR(20) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.order_items (\n",
    "    order_item_id                INT           PRIMARY KEY,\n",
    "    order_id                     INT           NOT NULL,\n",
    "    product_id                   INT           NOT NULL,\n",
    "    quantity                     SMALLINT      NOT NULL,\n",
    "    item_list_price_at_sale      NUMERIC(10,2) NOT NULL,\n",
    "    item_standard_cost_at_sale   NUMERIC(10,2)\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02805d0c",
   "metadata": {},
   "source": [
    "### Функции обработки исходных данных и загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка to boolean\n",
    "def str_to_bool(value: str) -> bool:\n",
    "    if value is None:\n",
    "        raise ValueError(\"NULL boolean\")\n",
    "    v = value.strip().lower()\n",
    "    if v in (\"yes\", \"y\", \"true\", \"1\"):\n",
    "        return True\n",
    "    if v in (\"no\", \"n\", \"false\", \"0\"):\n",
    "        return False\n",
    "    raise ValueError(f\"Invalid boolean value: {value}\")\n",
    "\n",
    "# обработка пола\n",
    "def normalize_gender(value: str) -> str | None:\n",
    "    if value is None:\n",
    "        return None\n",
    "    v = value.strip().lower()\n",
    "    if v == \"\":\n",
    "        return None\n",
    "\n",
    "    # учёт опечаток\n",
    "    female_variants = {\"f\", \"female\", \"femal\", \"femla\", \"femail\", \"femael\", \"fem\"}\n",
    "    male_variants   = {\"m\", \"male\", \"mela\", \"mael\", \"mlae\"}\n",
    "    if v in female_variants:\n",
    "        return \"F\"\n",
    "    if v in male_variants:\n",
    "        return \"M\"\n",
    "    if v[0] == \"f\":\n",
    "        return \"F\"\n",
    "    if v[0] == \"m\":\n",
    "        return \"M\"\n",
    "    return None\n",
    "\n",
    "def exec_sql(sql: str):\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "\n",
    "def load_customer():\n",
    "    fixed = 0\n",
    "    unknown = 0\n",
    "    total = 0\n",
    "\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    path = os.path.join(DATA_PATH, \"customer.csv\")\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        # idempotent\n",
    "        cur.execute(\"TRUNCATE TABLE public.customer;\")\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f, delimiter=\";\")\n",
    "            for r in reader:\n",
    "                total += 1\n",
    "\n",
    "                g_raw = r[\"gender\"]\n",
    "                g_norm = normalize_gender(g_raw)\n",
    "\n",
    "                # статистика\n",
    "                if (g_raw or \"\").strip() != \"\" and g_norm is None:\n",
    "                    unknown += 1\n",
    "                elif (g_raw or \"\").strip().lower() not in (\"\", \"f\", \"m\", \"female\", \"male\") and g_norm is not None:\n",
    "                    fixed += 1\n",
    "\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO public.customer VALUES (\n",
    "                        %(customer_id)s,\n",
    "                        %(first_name)s,\n",
    "                        %(last_name)s,\n",
    "                        %(gender)s,\n",
    "                        %(dob)s,\n",
    "                        %(job_title)s,\n",
    "                        %(job_industry_category)s,\n",
    "                        %(wealth_segment)s,\n",
    "                        %(deceased_indicator)s,\n",
    "                        %(owns_car)s,\n",
    "                        %(address)s,\n",
    "                        %(postcode)s,\n",
    "                        %(state)s,\n",
    "                        %(country)s,\n",
    "                        %(property_valuation)s\n",
    "                    )\n",
    "                \"\"\", {\n",
    "                    \"customer_id\": int(r[\"customer_id\"]),\n",
    "                    \"first_name\": r[\"first_name\"],\n",
    "                    \"last_name\": r[\"last_name\"] or None,\n",
    "                    \"gender\": g_norm,\n",
    "                    \"dob\": r[\"DOB\"] or None,\n",
    "                    \"job_title\": r[\"job_title\"] or None,\n",
    "                    \"job_industry_category\": r[\"job_industry_category\"] or None,\n",
    "                    \"wealth_segment\": r[\"wealth_segment\"],\n",
    "                    \"deceased_indicator\": str_to_bool(r[\"deceased_indicator\"]),\n",
    "                    \"owns_car\": str_to_bool(r[\"owns_car\"]),\n",
    "                    \"address\": r[\"address\"],\n",
    "                    \"postcode\": r[\"postcode\"],\n",
    "                    \"state\": r[\"state\"],\n",
    "                    \"country\": r[\"country\"],\n",
    "                    \"property_valuation\": int(r[\"property_valuation\"]),\n",
    "                })\n",
    "        conn.commit()\n",
    "    print(\n",
    "        f\"[customer] rows={total}, \"\n",
    "        f\"gender_fixed={fixed}, \"\n",
    "        f\"gender_unknown={unknown}\"\n",
    "    )\n",
    "\n",
    "def load_order_items():\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    path = os.path.join(DATA_PATH, \"order_items.csv\")\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(\"TRUNCATE TABLE public.order_items;\")\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for r in reader:\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO public.order_items VALUES (\n",
    "                        %(order_item_id)s,\n",
    "                        %(order_id)s,\n",
    "                        %(product_id)s,\n",
    "                        %(quantity)s,\n",
    "                        %(item_list_price_at_sale)s,\n",
    "                        %(item_standard_cost_at_sale)s\n",
    "                    )\n",
    "                \"\"\", {\n",
    "                    \"order_item_id\": int(r[\"order_item_id\"]),\n",
    "                    \"order_id\": int(r[\"order_id\"]),\n",
    "                    \"product_id\": int(r[\"product_id\"]),\n",
    "                    \"quantity\": int(float(r[\"quantity\"])),\n",
    "                    \"item_list_price_at_sale\": float(r[\"item_list_price_at_sale\"]),\n",
    "                    \"item_standard_cost_at_sale\": (\n",
    "                        float(r[\"item_standard_cost_at_sale\"])\n",
    "                        if r[\"item_standard_cost_at_sale\"] else None\n",
    "                    ),\n",
    "                })\n",
    "        conn.commit()\n",
    "\n",
    "def load_product_stage():\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    path = os.path.join(DATA_PATH, \"product.csv\")\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(\"TRUNCATE TABLE public.product_stage;\")\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for r in reader:\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO public.product_stage VALUES (\n",
    "                        %(product_id)s,\n",
    "                        %(brand)s,\n",
    "                        %(product_line)s,\n",
    "                        %(product_class)s,\n",
    "                        %(product_size)s,\n",
    "                        %(list_price)s,\n",
    "                        %(standard_cost)s\n",
    "                    )\n",
    "                \"\"\", {\n",
    "                    \"product_id\": int(r[\"product_id\"]),\n",
    "                    \"brand\": r[\"brand\"],\n",
    "                    \"product_line\": r[\"product_line\"],\n",
    "                    \"product_class\": r[\"product_class\"],\n",
    "                    \"product_size\": r[\"product_size\"],\n",
    "                    \"list_price\": float(r[\"list_price\"]),\n",
    "                    \"standard_cost\": (\n",
    "                        float(r[\"standard_cost\"]) if r[\"standard_cost\"] else None\n",
    "                    ),\n",
    "                })\n",
    "        conn.commit()\n",
    "        \n",
    "def rebuild_product():\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    sql = \"\"\"\n",
    "    TRUNCATE TABLE public.product;\n",
    "    INSERT INTO public.product\n",
    "    SELECT\n",
    "        product_id,\n",
    "        brand,\n",
    "        product_line,\n",
    "        product_class,\n",
    "        product_size,\n",
    "        list_price,\n",
    "        standard_cost\n",
    "    FROM (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY product_id\n",
    "                ORDER BY list_price DESC\n",
    "            ) AS rn\n",
    "        FROM public.product_stage\n",
    "    ) t\n",
    "    WHERE rn = 1;\n",
    "    \"\"\"\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "\n",
    "def load_simple(table, filename, delimiter=\",\"):\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    path = os.path.join(DATA_PATH, filename)\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(f\"TRUNCATE TABLE public.{table};\")\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f, delimiter=delimiter)\n",
    "            cols = reader.fieldnames\n",
    "            sql = f\"\"\"\n",
    "                INSERT INTO public.{table} ({\", \".join(cols)})\n",
    "                VALUES ({\", \".join([\"%s\"] * len(cols))})\n",
    "            \"\"\"\n",
    "            for r in reader:\n",
    "                cur.execute(sql, [r[c] or None for c in cols])\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b67758",
   "metadata": {},
   "source": [
    "### Запуск DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=\"daily_parallel_insert_clear\",\n",
    "    start_date=datetime(2025, 1, 1, tz=\"Europe/Moscow\"),\n",
    "    schedule=\"0 19 * * *\",\n",
    "    catchup=False,\n",
    "    tags=[\"etl\", \"strict\", \"public\"],\n",
    ") as dag:\n",
    "\n",
    "    create_tables = PythonOperator(\n",
    "        task_id=\"create_tables\",\n",
    "        python_callable=exec_sql,\n",
    "        op_kwargs={\"sql\": DDL_SQL},\n",
    "    )\n",
    "\n",
    "    t_customer = PythonOperator(\n",
    "        task_id=\"load_customer\",\n",
    "        python_callable=load_customer,\n",
    "    )\n",
    "\n",
    "    t_product_stage = PythonOperator(\n",
    "    task_id=\"load_product_stage\",\n",
    "    python_callable=load_product_stage,\n",
    "    )\n",
    "\n",
    "    t_product_rebuild = PythonOperator(\n",
    "        task_id=\"rebuild_product\",\n",
    "        python_callable=rebuild_product,\n",
    "    )\n",
    "\n",
    "    t_orders = PythonOperator(\n",
    "        task_id=\"load_orders\",\n",
    "        python_callable=load_simple,\n",
    "        op_kwargs={\"table\": \"orders\", \"filename\": \"orders.csv\"},\n",
    "    )\n",
    "\n",
    "    t_order_items = PythonOperator(\n",
    "    task_id=\"load_order_items\",\n",
    "    python_callable=load_order_items,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663270a",
   "metadata": {},
   "source": [
    "### Запуск тасков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # cначала всегда создаём таблицы\n",
    "    create_tables >> [\n",
    "    t_customer,\n",
    "    t_orders,\n",
    "    t_order_items,\n",
    "    t_product_stage\n",
    "    ]\n",
    "\n",
    "    # product строится только после staging\n",
    "    t_product_stage >> t_product_rebuild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c9902",
   "metadata": {},
   "source": [
    "## Шаг 2. Далее выполнить следующие запросы, записав ответы в отдельные файлы (параллельные task):\n",
    "- Найти имена и фамилии клиентов с ТОП-3 минимальной и ТОП-3 максимальной суммой транзакций за весь период (учесть клиентов, у которых нет заказов).\n",
    "- Найти ТОП-5 клиентов (по общему доходу) в каждом сегменте благосостояния (wealth_segment). Вывести имя, фамилию, сегмент и общий доход. Если в сегменте менее 5 клиентов, вывести всех."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e887d",
   "metadata": {},
   "source": [
    "### Формулируем запросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_TOP3 = \"\"\"\n",
    "WITH client_revenue AS (\n",
    "    SELECT\n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        COALESCE(\n",
    "            SUM(oi.quantity * oi.item_list_price_at_sale),\n",
    "            0\n",
    "        ) AS total_revenue\n",
    "    FROM public.customer c\n",
    "    LEFT JOIN public.orders o\n",
    "        ON c.customer_id = o.customer_id\n",
    "    LEFT JOIN public.order_items oi\n",
    "        ON o.order_id = oi.order_id\n",
    "    GROUP BY\n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT *,\n",
    "           ROW_NUMBER() OVER (ORDER BY total_revenue ASC)  AS rn_min,\n",
    "           ROW_NUMBER() OVER (ORDER BY total_revenue DESC) AS rn_max\n",
    "    FROM client_revenue\n",
    ")\n",
    "SELECT\n",
    "    first_name,\n",
    "    last_name,\n",
    "    total_revenue,\n",
    "    CASE\n",
    "        WHEN rn_min <= 3 THEN 'MIN'\n",
    "        WHEN rn_max <= 3 THEN 'MAX'\n",
    "    END AS category\n",
    "FROM ranked\n",
    "WHERE rn_min <= 3\n",
    "   OR rn_max <= 3\n",
    "ORDER BY category, total_revenue;\n",
    "\"\"\"\n",
    "\n",
    "SQL_TOP5 = \"\"\"\n",
    "WITH client_revenue AS (\n",
    "    SELECT\n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.wealth_segment,\n",
    "        COALESCE(\n",
    "            SUM(oi.quantity * oi.item_list_price_at_sale),\n",
    "            0\n",
    "        ) AS total_revenue\n",
    "    FROM public.customer c\n",
    "    LEFT JOIN public.orders o\n",
    "        ON c.customer_id = o.customer_id\n",
    "    LEFT JOIN public.order_items oi\n",
    "        ON o.order_id = oi.order_id\n",
    "    GROUP BY\n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.wealth_segment\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT *,\n",
    "           ROW_NUMBER() OVER (\n",
    "               PARTITION BY wealth_segment\n",
    "               ORDER BY total_revenue DESC\n",
    "           ) AS rn\n",
    "    FROM client_revenue\n",
    ")\n",
    "SELECT\n",
    "    first_name,\n",
    "    last_name,\n",
    "    wealth_segment,\n",
    "    total_revenue\n",
    "FROM ranked\n",
    "WHERE rn <= 5\n",
    "ORDER BY wealth_segment, total_revenue DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e3d21",
   "metadata": {},
   "source": [
    "### Функция записи результата в csv-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(sql: str, output_filename: str):\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "    output_path = os.path.join(\"/opt/airflow/results\", output_filename)\n",
    "\n",
    "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(columns)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570b7d0",
   "metadata": {},
   "source": [
    "### Доработка DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d320085",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=\"daily_parallel_insert_clear\",\n",
    "    start_date=datetime(2025, 1, 1, tz=\"Europe/Moscow\"),\n",
    "    schedule=\"0 19 * * *\",\n",
    "    catchup=False,\n",
    "    tags=[\"etl\", \"strict\", \"public\"],\n",
    ") as dag:\n",
    "    t_top3 = PythonOperator(\n",
    "    task_id=\"top3_clients\",\n",
    "    python_callable=to_csv,\n",
    "    op_kwargs={\n",
    "        \"sql\": SQL_TOP3,\n",
    "        \"output_filename\": \"top3_clients.csv\",\n",
    "        },\n",
    "    )\n",
    "    t_top5 = PythonOperator(\n",
    "    task_id=\"top5_clients\",\n",
    "    python_callable=to_csv,\n",
    "    op_kwargs={\n",
    "        \"sql\": SQL_TOP5,\n",
    "        \"output_filename\": \"top5_clients.csv\",\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111abdad",
   "metadata": {},
   "source": [
    "### Дополняем таски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01254bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # выполняем запросы по заданию\n",
    "    [\n",
    "    t_customer,\n",
    "    t_orders,\n",
    "    t_order_items,\n",
    "    t_product_rebuild,\n",
    "        ] >> t_top3\n",
    "\n",
    "    [\n",
    "    t_customer,\n",
    "    t_orders,\n",
    "    t_order_items,\n",
    "    t_product_rebuild,\n",
    "        ] >> t_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2faca7",
   "metadata": {},
   "source": [
    "## Шаг 3. Проверить, что запросы из пункта выше не вернули нулевое количество строк. \n",
    "В случае непрохождения проверки отправить уведомление на почту (print ошибки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_query_not_empty(sql: str):\n",
    "    hook = PostgresHook(postgres_conn_id=CONN_ID)\n",
    "    sql_clean = sql.strip().rstrip(\";\")\n",
    "    check_sql = f\"\"\"\n",
    "    SELECT COUNT(*) FROM (\n",
    "        {sql_clean}\n",
    "    ) t\n",
    "    \"\"\"\n",
    "    with hook.get_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(check_sql)\n",
    "        cnt = cur.fetchone()[0]\n",
    "    if cnt == 0:\n",
    "        print(\"Ошибка\")\n",
    "        raise ValueError(\"No rows returned - ERROR!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505c954",
   "metadata": {},
   "source": [
    "### Доработка DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=\"daily_parallel_insert_clear\",\n",
    "    start_date=datetime(2025, 1, 1, tz=\"Europe/Moscow\"),\n",
    "    schedule=\"0 19 * * *\",\n",
    "    catchup=False,\n",
    "    tags=[\"etl\", \"strict\", \"public\"],\n",
    ") as dag:\n",
    "\n",
    "    t_check_top3 = PythonOperator(\n",
    "        task_id=\"check_top3_not_empty\",\n",
    "        python_callable=assert_query_not_empty,\n",
    "        op_kwargs={\"sql\": SQL_TOP3},\n",
    "        )\n",
    "\n",
    "    t_check_top5 = PythonOperator(\n",
    "        task_id=\"check_top5_not_empty\",\n",
    "        python_callable=assert_query_not_empty,\n",
    "        op_kwargs={\"sql\": SQL_TOP5},\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cbb5d1",
   "metadata": {},
   "source": [
    "### Дополнение тасков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    [\n",
    "    t_customer,\n",
    "    t_orders,\n",
    "    t_order_items,\n",
    "    t_product_rebuild,\n",
    "        ] >> t_top3 >> t_check_top3\n",
    "    [\n",
    "    t_customer,\n",
    "    t_orders,\n",
    "    t_order_items,\n",
    "    t_product_rebuild,\n",
    "        ] >> t_top5 >> t_check_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e5b178",
   "metadata": {},
   "source": [
    "## Шаг 4. Вывести сообщение об успешном или неуспешном выполнении DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491439f",
   "metadata": {},
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_success():\n",
    "    print(\"Успешно\")\n",
    "\n",
    "def print_failure():\n",
    "    print(\"Ошибка\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70203053",
   "metadata": {},
   "source": [
    "### Доработка DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d802538",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=\"daily_parallel_insert_clear\",\n",
    "    start_date=datetime(2025, 1, 1, tz=\"Europe/Moscow\"),\n",
    "    schedule=\"0 19 * * *\",\n",
    "    catchup=False,\n",
    "    tags=[\"etl\", \"strict\", \"public\"],\n",
    ") as dag:\n",
    "    \n",
    "    t_success = PythonOperator(\n",
    "        task_id=\"print_success\",\n",
    "        python_callable=print_success,\n",
    "        trigger_rule=\"all_success\",\n",
    "        )\n",
    "\n",
    "    t_failure = PythonOperator(\n",
    "        task_id=\"print_failure\",\n",
    "        python_callable=print_failure,\n",
    "        trigger_rule=\"one_failed\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d2c40a",
   "metadata": {},
   "source": [
    "### Добавление тасков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a28f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    [t_check_top3, t_check_top5] >> t_success   \n",
    "    [t_check_top3, t_check_top5] >> t_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ba6bf-410a-4e42-8401-72ee17e11f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
